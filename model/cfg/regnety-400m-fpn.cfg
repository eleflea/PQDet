[net]
channels=3

# simple stem in
[convolutional]
filters=32
size=3
pad=1
stride=2
batch_normalize=1
activation=relu

# stage 1 (1/1)
# projection
[convolutional]
filters=48
size=1
stride=2
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=48
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=48
groups=6
size=3
stride=2
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=8
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=48
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=48
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-9
activation=relu

# stage 2 (1/3)
# projection
[convolutional]
filters=104
size=1
stride=2
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=104
groups=13
size=3
stride=2
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=12
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-9
activation=relu

# stage 2 (2/3)
[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=104
groups=13
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=26
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 2 (3/3)
[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=104
groups=13
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=26
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=104
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 3 (1/6)
# projection
[convolutional]
filters=208
size=1
stride=2
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=2
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=26
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-9
activation=relu

# stage 3 (2/6)
[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 3 (3/6)
[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 3 (4/6)
[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 3 (5/6)
[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 3 (6/6)
[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=208
groups=26
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=208
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 4 (1/6)
# projection
[convolutional]
filters=440
size=1
stride=2
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=2
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=52
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-9
activation=relu

# stage 4 (2/6)
[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=110
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 4 (3/6)
[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=110
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 4 (4/6)
[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=110
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 4 (5/6)
[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=110
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

# stage 4 (6/6)
[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=440
groups=55
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[avgpool]

[convolutional]
filters=110
size=1
stride=1
pad=1
batch_normalize=0
activation=relu

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=0
activation=logistic

[scale_channels]
from=-4

[convolutional]
filters=440
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-8
activation=relu

#########################

# detect large
# block 1
# projection
[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
groups=22
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-5
activation=relu

# block 2
[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
groups=22
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

# block 3
[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
groups=22
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=352
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

[convolutional]
filters=75
size=1
stride=1
pad=1
activation=linear

[yolo]
classes=20
ignore_thresh = .5
bbox_loss=l1
l1_loss_gain=0.05

# merge to middle
[route]
layers = -7

[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 86

# detect middle
# block 1
# projection
[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
groups=11
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-5
activation=relu

# block 2
[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
groups=11
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

# block 3
[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
groups=11
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=176
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

[convolutional]
filters=75
size=1
stride=1
pad=1
activation=linear

[yolo]
classes=20
ignore_thresh = .5
bbox_loss=l1
l1_loss_gain=0.05

# merge to small
[route]
layers = -7

[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 36

# detect small
# block 1
# projection
[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[route]
layers=-2

[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
groups=5
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-5
activation=relu

# block 2
[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
groups=5
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

# block 3
[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
groups=5
size=3
stride=1
pad=1
batch_normalize=1
activation=relu

[convolutional]
filters=80
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[shortcut]
from=-4
activation=relu

[convolutional]
filters=75
size=1
stride=1
pad=1
activation=linear

[yolo]
classes=20
ignore_thresh = .5
bbox_loss=l1
l1_loss_gain=0.05